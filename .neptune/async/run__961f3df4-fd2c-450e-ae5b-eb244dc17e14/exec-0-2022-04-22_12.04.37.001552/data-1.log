{"obj": {"type": "AssignString", "path": ["sys", "name"], "value": "Untitled"}, "version": 1}
{"obj": {"type": "AssignString", "path": ["sys", "description"], "value": ""}, "version": 2}
{"obj": {"type": "AssignString", "path": ["sys", "hostname"], "value": "DESKTOP-J9LNDPA"}, "version": 3}
{"obj": {"type": "AssignBool", "path": ["sys", "failed"], "value": false}, "version": 4}
{"obj": {"type": "ClearStringLog", "path": ["monitoring", "stdout"]}, "version": 5}
{"obj": {"type": "ClearStringLog", "path": ["monitoring", "stderr"]}, "version": 6}
{"obj": {"type": "AssignString", "path": ["source_code", "entrypoint"], "value": "KD_main.py"}, "version": 7}
{"obj": {"type": "UploadFileSet", "path": ["source_code", "files"], "file_globs": ["f:\\EarEEG_KnowledgeDistillation\\KD_main.py"], "reset": "False"}, "version": 8}
{"obj": {"type": "ConfigFloatSeries", "path": ["monitoring", "cpu"], "min": 0.0, "max": 100.0, "unit": "%"}, "version": 9}
{"obj": {"type": "ClearFloatLog", "path": ["monitoring", "cpu"]}, "version": 10}
{"obj": {"type": "ConfigFloatSeries", "path": ["monitoring", "memory"], "min": 0.0, "max": 7.880100250244141, "unit": "GB"}, "version": 11}
{"obj": {"type": "ClearFloatLog", "path": ["monitoring", "memory"]}, "version": 12}
{"obj": {"type": "ConfigFloatSeries", "path": ["monitoring", "gpu"], "min": 0.0, "max": 100.0, "unit": "%"}, "version": 13}
{"obj": {"type": "ClearFloatLog", "path": ["monitoring", "gpu"]}, "version": 14}
{"obj": {"type": "ConfigFloatSeries", "path": ["monitoring", "gpu_memory"], "min": 0.0, "max": 2.0, "unit": "GB"}, "version": 15}
{"obj": {"type": "ClearFloatLog", "path": ["monitoring", "gpu_memory"]}, "version": 16}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stdout"], "values": [{"value": "===========================================================Training Epoch : [1/100] ===========================================================================================================>", "step": null, "ts": 1650609278.4370224}]}, "version": 17}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stdout"], "values": [{"value": "\n", "step": null, "ts": 1650609278.4400156}]}, "version": 18}
{"obj": {"type": "LogFloats", "path": ["monitoring", "cpu"], "values": [{"value": 22.0, "step": null, "ts": 1650609278.4304526}]}, "version": 19}
{"obj": {"type": "LogFloats", "path": ["monitoring", "memory"], "values": [{"value": 4.653350830078125, "step": null, "ts": 1650609278.4304526}]}, "version": 20}
{"obj": {"type": "LogFloats", "path": ["monitoring", "gpu_memory"], "values": [{"value": 0.19374847412109375, "step": null, "ts": 1650609278.4304526}]}, "version": 21}
{"obj": {"type": "LogFloats", "path": ["monitoring", "cpu"], "values": [{"value": 21.1, "step": null, "ts": 1650609288.4638233}]}, "version": 22}
{"obj": {"type": "LogFloats", "path": ["monitoring", "memory"], "values": [{"value": 6.0616912841796875, "step": null, "ts": 1650609288.4638233}]}, "version": 23}
{"obj": {"type": "LogFloats", "path": ["monitoring", "gpu"], "values": [{"value": 4.0, "step": null, "ts": 1650609288.4638233}]}, "version": 24}
{"obj": {"type": "LogFloats", "path": ["monitoring", "gpu_memory"], "values": [{"value": 0.6579208374023438, "step": null, "ts": 1650609288.4638233}]}, "version": 25}
{"obj": {"type": "LogStrings", "path": ["monitoring", "traceback"], "values": [{"value": "An uncaught exception occurred while run was active on worker DESKTOP-J9LNDPA.", "step": null, "ts": 1650609295.6035752}, {"value": "Marking run as failed", "step": null, "ts": 1650609295.6035752}, {"value": "Traceback:", "step": null, "ts": 1650609295.6035752}, {"value": "  File \"f:\\EarEEG_KnowledgeDistillation\\KD_main.py\", line 95, in <module>\n    KD_online_training(Net_s,Net_t,train_data_loader,val_data_loader,criterion_ce,criterion_mse,optimizer_t, optimizer_s,experiment,n_epochs,device,is_neptune=True)\n", "step": null, "ts": 1650609295.6035752}, {"value": "  File \"f:\\EarEEG_KnowledgeDistillation\\Model\\Training.py\", line 322, in KD_online_training\n    outputs,cls_s_feat,_ = Net_s(sig1.float().to(device), sig2.float().to(device), sig3.float().to(device),finetune = True)\n", "step": null, "ts": 1650609295.6035752}, {"value": "  File \"C:\\Users\\MithunjhaAnandakumar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n", "step": null, "ts": 1650609295.6035752}, {"value": "  File \"f:\\EarEEG_KnowledgeDistillation\\Model\\CrossModalTransformer.py\", line 267, in forward\n    ff_eog = self.eog_ff(eog_new)\n", "step": null, "ts": 1650609295.6035752}, {"value": "  File \"C:\\Users\\MithunjhaAnandakumar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n", "step": null, "ts": 1650609295.6035752}, {"value": "  File \"f:\\EarEEG_KnowledgeDistillation\\Model\\CrossModalTransformer.py\", line 220, in forward\n    src2 = self.linear2(self.dropout1(self.relu(self.linear1(src))))\n", "step": null, "ts": 1650609295.6035752}, {"value": "  File \"C:\\Users\\MithunjhaAnandakumar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n", "step": null, "ts": 1650609295.6035752}]}, "version": 26}
{"obj": {"type": "LogStrings", "path": ["monitoring", "traceback"], "values": [{"value": "  File \"C:\\Users\\MithunjhaAnandakumar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n", "step": null, "ts": 1650609295.6035752}, {"value": "  File \"C:\\Users\\MithunjhaAnandakumar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n", "step": null, "ts": 1650609295.6035752}, {"value": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 2.00 GiB total capacity; 999.65 MiB already allocated; 14.55 MiB free; 1.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF", "step": null, "ts": 1650609295.6035752}]}, "version": 27}
{"obj": {"type": "AssignBool", "path": ["sys", "failed"], "value": true}, "version": 28}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "Traceback (most recent call last):\n", "step": null, "ts": 1650609295.605463}]}, "version": 29}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "  File \"f:\\EarEEG_KnowledgeDistillation\\KD_main.py\", line 95, in <module>\n", "step": null, "ts": 1650609295.6064682}]}, "version": 30}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "    ", "step": null, "ts": 1650609295.609788}]}, "version": 31}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "KD_online_training(Net_s,Net_t,train_data_loader,val_data_loader,criterion_ce,criterion_mse,optimizer_t, optimizer_s,experiment,n_epochs,device,is_neptune=True)", "step": null, "ts": 1650609295.609788}]}, "version": 32}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "\n", "step": null, "ts": 1650609295.610792}]}, "version": 33}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "  File \"f:\\EarEEG_KnowledgeDistillation\\Model\\Training.py\", line 322, in KD_online_training\n", "step": null, "ts": 1650609295.613752}]}, "version": 34}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "    ", "step": null, "ts": 1650609295.614818}]}, "version": 35}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "outputs,cls_s_feat,_ = Net_s(sig1.float().to(device), sig2.float().to(device), sig3.float().to(device),finetune = True)", "step": null, "ts": 1650609295.6156144}]}, "version": 36}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "\n", "step": null, "ts": 1650609295.6166034}]}, "version": 37}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "  File \"C:\\Users\\MithunjhaAnandakumar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl\n", "step": null, "ts": 1650609295.6175992}]}, "version": 38}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "    ", "step": null, "ts": 1650609295.6186013}]}, "version": 39}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "return forward_call(*input, **kwargs)", "step": null, "ts": 1650609295.6186013}]}, "version": 40}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "\n", "step": null, "ts": 1650609295.6195927}]}, "version": 41}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "  File \"f:\\EarEEG_KnowledgeDistillation\\Model\\CrossModalTransformer.py\", line 267, in forward\n", "step": null, "ts": 1650609295.6205916}]}, "version": 42}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "    ", "step": null, "ts": 1650609295.6205916}]}, "version": 43}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "ff_eog = self.eog_ff(eog_new)", "step": null, "ts": 1650609295.6205916}]}, "version": 44}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "\n", "step": null, "ts": 1650609295.6215878}]}, "version": 45}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "  File \"C:\\Users\\MithunjhaAnandakumar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl\n", "step": null, "ts": 1650609295.6215878}]}, "version": 46}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "    ", "step": null, "ts": 1650609295.6225889}]}, "version": 47}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "return forward_call(*input, **kwargs)", "step": null, "ts": 1650609295.6225889}]}, "version": 48}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "\n", "step": null, "ts": 1650609295.623616}]}, "version": 49}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "  File \"f:\\EarEEG_KnowledgeDistillation\\Model\\CrossModalTransformer.py\", line 220, in forward\n", "step": null, "ts": 1650609295.623616}]}, "version": 50}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "    ", "step": null, "ts": 1650609295.62458}]}, "version": 51}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "src2 = self.linear2(self.dropout1(self.relu(self.linear1(src))))", "step": null, "ts": 1650609295.62458}]}, "version": 52}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "\n", "step": null, "ts": 1650609295.62458}]}, "version": 53}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "  File \"C:\\Users\\MithunjhaAnandakumar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl\n", "step": null, "ts": 1650609295.625576}]}, "version": 54}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "    ", "step": null, "ts": 1650609295.6265838}]}, "version": 55}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "return forward_call(*input, **kwargs)", "step": null, "ts": 1650609295.6265838}]}, "version": 56}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "\n", "step": null, "ts": 1650609295.6265838}]}, "version": 57}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "  File \"C:\\Users\\MithunjhaAnandakumar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 103, in forward\n", "step": null, "ts": 1650609295.6285815}]}, "version": 58}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "    ", "step": null, "ts": 1650609295.6305633}]}, "version": 59}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "return F.linear(input, self.weight, self.bias)", "step": null, "ts": 1650609295.6305633}]}, "version": 60}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "\n", "step": null, "ts": 1650609295.6315863}]}, "version": 61}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "  File \"C:\\Users\\MithunjhaAnandakumar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py\", line 1848, in linear\n", "step": null, "ts": 1650609295.6315863}]}, "version": 62}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "    ", "step": null, "ts": 1650609295.6355507}]}, "version": 63}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "return torch._C._nn.linear(input, weight, bias)", "step": null, "ts": 1650609295.6355507}]}, "version": 64}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "\n", "step": null, "ts": 1650609295.6355507}]}, "version": 65}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "RuntimeError", "step": null, "ts": 1650609295.6355507}]}, "version": 66}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": ": ", "step": null, "ts": 1650609295.6365473}]}, "version": 67}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 2.00 GiB total capacity; 999.65 MiB already allocated; 14.55 MiB free; 1.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF", "step": null, "ts": 1650609295.6365473}]}, "version": 68}
{"obj": {"type": "LogStrings", "path": ["monitoring", "stderr"], "values": [{"value": "\n", "step": null, "ts": 1650609295.637546}]}, "version": 69}
